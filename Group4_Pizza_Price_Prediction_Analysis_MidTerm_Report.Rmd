---
title: "Pizza price prediction and Location analysis"
subtitle: "Midterm Report"
author: "KunJung Lin, Roshan Kotian, Mark Trovinger"
date: "3/18/2020"
output: 
  pdf_document : 
    toc: true
    number_sections: true
    toc_depth: 4
---

<style>
body, h1, h2, h3, h4 {
    font-family: "Bookman", serif;
}

body {
    color: #333333;
}
a, a:hover {
    color: red;
}
pre {
    font-size: 10px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

# Description of Dataset
The dataset in question is from Datafiniti, a company that provides businesses with a wide variety of information on retail products, properties, and companies. The data is a list of over 3500 pizzas from multiple restaurants across the United States. 

The dataset is 4.7 MB unzipped, which does not make the big dataset *data* by any definition, but has 10,000 rows, which makes it large enough for our purposes.  

# Purpose of this project
The purpose of this project is to present a theoretical business owner with a workup of what the likely price should be for new pizzas. To do so, we will be using two different predictive models, one that is simpler and one that is more complex. The purpose of having two different models is to illustrate how much value could be derived from a more sophisticated approach to solving the problem versus a more straightforward, cheaper solution.

# Intended audience for project
The intended audience for this project would be the owner of a pizza restaurant that is looking to potentially expand its business or a new owner looking to get started in the pizza business. The final report should not be overly technical, as making a report too technical can often turn off stakeholders and make it more likely that a proposed solution will not be implemented. 

```{r library, message=FALSE, warning=FALSE}
# Import libraries
library(tidyverse)
library(dplyr)
library(readr)
library(ggplot2)
library(sqldf)
library(randomForest)
library(knitr)
library(kableExtra)

```

```{r read_data, message=FALSE, warning=FALSE}
# Read Dataset
# Copy whole data to `pizza` and do the tidying or manipulating
raw_pizza <- read_csv("Datafiniti_Pizza_Restaurants_and_the_Pizza_They_Sell_May19.csv")
pizza <- raw_pizza
```

# Manipulate (tidy) the Dataset

* Remove the Columns Have the Same Value
```{r tidy_1}
pizza$country <- NULL
#All "US"

pizza$menus.currency <- NULL
pizza$priceRangeCurrency <- NULL
#All "USD"
```

* Select Specific Columns to Data Frame

  We split some columns to another table because for some predictions, we do not need to use such a wide data frame. 
  If we can split them into some small data frame, it can make the data frame more readable and useable.
  At this point, we split it into two tables, which are `pizza_store_info` and `pizza_info`.

  + `pizza_store_info` stores the information about the store.
  + `pizza_info` stores the information about pizzas and using `id` to connect with `pizza_store_info`.

  After we do some research, the `menus.amountMax` and `menus.amountMin` might mean one specific flavor of pizza that has the price for a whole pizza or a slice if two values are different. 
  To use the data correctly, we need to check the `menus.description` and `menus.name` to see if there has some detail of the price of not.
  At the same time, we also need to remove the data that the `menus.amountMax` or `menus.amountMin` is `0`.

For the `pizza`, we still keep this variable. In case we need to use the data that has been removed.
```{r tidy_2}
# Select the information of pizza store.
pizza_store_info <- pizza %>% 
  select(id, address, categories, primaryCategories, 
         city, keys, latitude, longitude, name, postalCode, 
         province)

# Only keep unique/distinct rows 
pizza_store_info <- distinct(pizza_store_info)

# Select the information of pizza
pizza_info <- pizza %>% 
  select(id, menuPageURL, menus.amountMax, menus.amountMin, menus.description, menus.name)

# Remove the data that has 0 value
pizza_info <- pizza_info[!(pizza_info$menus.amountMax == 0.00 | pizza_info$menus.amountMin == 0.00),]
```

* Correct the Data Type of Data Frame

  After some manipulate, then we need to do correct some data type of columns. 
  For example, `province` should be a factor instead of character.

```{r tidy_3}
pizza_store_info$province <- as.factor(pizza_store_info$province)
pizza$province <- as.factor(pizza$province)

```
* Summary of the Data Frame
```{r summary_1}
# pizza
head(pizza) %>%
  select(city, province, address, name, menus.amountMax, menus.name) %>%
  kable(booktabs = T, align = "lccccc", "pandoc", caption = "Summary of `pizza`") 
```

\newpage
```{r summary_2}
# pizza_info
head(pizza_info) %>%
  select(menus.amountMax, menus.name) %>%
  kable(booktabs = T, align = "cc", "pandoc", caption = "Summary of `pizza_info`") 

# pizza_store_info
head(pizza_store_info) %>%
  select(city, province, address, name) %>%
  kable(booktabs = T, align = "lccc", "pandoc", caption = "Summary of `pizza_store_info`") 
```

* Renaming column names of pizza_info dataset for better readability

  `pizza_info` data set consists of raw column names which can be modified to more informational names for better readability
```{r tidy_4}

names(pizza_info)[names(pizza_info)=="menus.amountMax"] <- "pizzaMaxPrice"
names(pizza_info)[names(pizza_info)=="menus.amountMin"] <- "pizzaMinPrice"
names(pizza_info)[names(pizza_info)=="menus.description"] <- "pizzaDescription"
names(pizza_info)[names(pizza_info)=="menus.name"] <- "pizzaName"
  
```


# Visualize the Data
```{r visu_plot1, warning=FALSE, fig.height = 4, fig.width = 5, fig.align = "center"}
# Show the top 25 number of store sorted by province

pizza_store_count <- pizza_store_info %>% group_by(province) %>% summarise(num = n())
pizza_store_count <- arrange(pizza_store_count, -num)

ggplot(pizza_store_count[1:10,], aes( x = reorder(province,-num), y = num, fill = province)) + 
  geom_histogram(stat="identity", position="identity") +
  labs(x = 'States', y = "Pizza store number") + 
  ggtitle("Top 10 City has the most pizza stores")

```

```{r visu_plot2, fig.height = 4, fig.width = 7, fig.align = "center"}
# Show the menu.amountMax(< 75) of all the pizza

pizza %>%
  filter(menus.amountMax < 75) %>%
  ggplot(aes(x = province, y = menus.amountMax, color = province)) + 
  geom_point() +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.4))+
  labs(x = 'States', y = "Max Amount") +
  ggtitle("Pizza price in different state")

```

```{r visu_plot3, fig.height = 5, fig.width = 7, fig.align = "center"}
# City having more than 100 pizza places

pizza_places_per_city <- sqldf("select city, count(name) as pizza_places
                                    from pizza
                                    group by city
                                    having count(name) > 100
                                    order by pizza_places desc")

# Boxplot visualization
ggplot(pizza_places_per_city, aes(x = reorder(city, pizza_places), y =  pizza_places, fill = city)) +
  geom_bar(stat = "identity", width=0.5 ) +
  theme(axis.text.x = element_text(size  = 10,
                                hjust = 1,
                                vjust = 1)) +
  labs(x = "City", y = "Pizza places") + 
  ggtitle("City having more than 100 pizza places") + 
  coord_flip()

```

```{r visu_plot4, fig.height = 5, fig.width = 8, fig.align = "center" }
# Commonly sold pizza menu across states

most_ordered_menu <- sqldf("select pizzaName, count(pizzaName) as total_sold
                            from pizza_info
                            group by pizzaName
                            having total_sold > 75
                            order by total_sold desc")

ggplot(most_ordered_menu, aes(x = reorder(pizzaName, total_sold), y = total_sold , fill = pizzaName)) +
  geom_bar(position = "stack", stat = "identity", width = 0.5) +
  theme(axis.text.x = element_text(size =10,
                                   hjust = 1,
                                   vjust = 1)) +
  labs(x = "Pizza Flavor", y = "Total sold") + 
  ggtitle("Commonly sold pizza menu across states") + 
  coord_flip()
```


## Model Proposal

The goal of the predictive model will be used in pricing pizza. We hypothesize that a more complex model, such as Random Forest Regression, will have a greater accuracy in predicting pricing than a simpler model, such as Linear Regression. 

While a more complicated model tends to require more compute resources to train, the trade-off is that the more complex model performs better, frequently dramatically. In this case, the difference in required compute resources is probably fairly small, but it would be interesting to see how well the two models compared.

We will be testing our hypothesis by looking at the accuracy rates for both the simpler model, and the more complex model. The model with a higher accuracy score will be the one recommended for use in the final report.

The main challenge that could cause issues is our relative lack of experience using R for machine learning. While some in our group have experience using machine learning models, that experience is in Python. This isn't an impossible obstacle to overcome, since we will be learning about modelling packages in R later in the course.



## Model Implementation

In this section, we will be discussing implementing the two models chosen for this project, Linear Regression and Random Forest Regression.

### Data Preprocessing

Before we can start building models, we need to prepare our data for the model building process. To start we create a data.frame that contains a subset of the dataset that includes both the pizza information and the store information. In order to have a response variable to build a model with, we will create a new column, avgPrice, that adds the minimum and maximum prices and divides by the number of menu items. Since we don't have the number of menu items, we can make an educated guess that it will be between 5 and 10 menu items. 

```{r data preprocess}
set.seed(42)
pizza_info_modelling <- pizza %>% 
  select(id, address, categories, primaryCategories, 
         city, keys, latitude, longitude, name, postalCode, 
         province, priceRangeMin, priceRangeMax)

pizza_info_modelling$city <- as.factor(pizza_info_modelling$city)

pizza_info_modelling$menuItems <- sample(5:10, size = nrow(pizza_info_modelling), replace = TRUE)

pizza_info_modelling$avgPrice <- (pizza_info_modelling$priceRangeMin + pizza_info_modelling$priceRangeMax) / (pizza_info_modelling$menuItems)

```

### Linear Regression

Now that we have a response variable to test against, we can look at the first model we tested for the project, Linear Regression. Linear Regression is a model that can be trained and deployed quickly, requiring far less compute resources than other, more complicated models. Because we are looking at the geographic location for how to price an average item from a pizza restraunt, it makes sense to examine the three location based variables in our data; city, state, and ZIP code.

```{r linear regression}
linear_model <- lm(avgPrice ~ city + province + postalCode, data = pizza_info_modelling)
```


### Random Forest Regression

Much like the Linear Regression model, the Random Forest will examine the relationship between the response variable and the dependent variables. Unlike with linear regression, random forests won't work with factors that have greater than 52 levels. For the purposes of the project, it means we are unable to use the city parameter from our data.

```{r random forest regression}
random_forest <- randomForest(avgPrice ~ province + postalCode, data = pizza_info_modelling, na.action = na.omit)
```

### Model Comparison

For the purposes of comparing the two models, we will look at the Mean Squared Error for both the Linear Regression model, and the Random Forest model. In the case of the Random Forest model, we need to look at the final element in the array mse, as it contains the cumulative MSE for the entire forest.

```{r model comparison}
rf_mse <- tail(random_forest$mse, 1)
linear_mse <- mean(linear_model$residuals^2)

# in order to plot, we need to create a new data.frame
plot_df <- data.frame(model = c('Linear Model', 'Random Forest'), MSE = c(linear_mse, rf_mse))

ggplot(data = plot_df, aes(x = model, y = MSE, fill = model)) +
  geom_bar(stat = "identity") +
  ggtitle("Mean Squared Error for Models")
```

As we can see from the plot, the Linear Model has a lower Mean Squared Error than the Random Forest. However, we cannot necessarily infer that the Linear Model would be the better choice, as we were not able to use all of the data. This isn't necessarily a weakness in the model, but rather would require a greater investment in data engineering, in order to parse the city column into a form that the model would accept.
